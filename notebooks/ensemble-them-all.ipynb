{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1467bdc",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4218305",
   "metadata": {},
   "source": [
    "Some experiments to get a good score for the [Identify Age-Related Conditions][0] kaggle competition.\n",
    "\n",
    "Start by importing commonly used modules that make it convenient to work with the fastai library. Some will be patched to make them work in non-standard ways but improve interactivity.\n",
    "\n",
    "[0]: https://www.kaggle.com/competitions/icr-identify-age-related-conditions\n",
    "\n",
    "On kaggle, attach the `pip-packages-icr` dataset then uncomment the following to install tabpfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a363a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tabpfn --no-index --find-links=file:///kaggle/input/pip-packages-icr/pip-packages\n",
    "#!mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "#!cp /kaggle/input/pip-packages-icr/pip-packages/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782631be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173d13e9",
   "metadata": {},
   "source": [
    "# Data Inspection\n",
    "\n",
    "Get the dataset appropriately whether we're in kaggle or not. If in kaggle, it is assumed the competition dataset has been connected to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e366e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icr-identify-age-related-conditions.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "competition_name = \"icr-identify-age-related-conditions\"\n",
    "\n",
    "is_kaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "if is_kaggle:\n",
    "    path = Path(f\"/kaggle/input/{competition_name}\")\n",
    "else:\n",
    "    import zipfile, kaggle\n",
    "    path = Path.home() / '.kaggle' / 'input' / competition_name\n",
    "    kaggle.api.competition_download_cli(competition_name, path=path.parent)\n",
    "    zipfile.ZipFile(f'{path}.zip').extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3172fa6",
   "metadata": {},
   "source": [
    "Load the datasets. It's a small dataset so we can set the `low_memory` pandas flag to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c643d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [Path('/home/krm/.kaggle/input/icr-identify-age-related-conditions/test.csv'),Path('/home/krm/.kaggle/input/icr-identify-age-related-conditions/greeks.csv'),Path('/home/krm/.kaggle/input/icr-identify-age-related-conditions/train.csv'),Path('/home/krm/.kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9578190d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>...</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ff2bfdfe9</td>\n",
       "      <td>0.209377</td>\n",
       "      <td>3109.03329</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>22.394407</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>9.812214</td>\n",
       "      <td>5.555634</td>\n",
       "      <td>...</td>\n",
       "      <td>7.298162</td>\n",
       "      <td>1.73855</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>11.339138</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2003.810319</td>\n",
       "      <td>22.136229</td>\n",
       "      <td>69.834944</td>\n",
       "      <td>0.120343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007255e47698</td>\n",
       "      <td>0.145282</td>\n",
       "      <td>978.76416</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>36.968889</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.632190</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>13.517790</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.568932</td>\n",
       "      <td>9.292698</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>27981.562750</td>\n",
       "      <td>29.135430</td>\n",
       "      <td>32.131996</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>013f2bd269f5</td>\n",
       "      <td>0.470030</td>\n",
       "      <td>2635.10654</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>32.360553</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.732840</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>12.824570</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>...</td>\n",
       "      <td>7.709560</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>1.198821</td>\n",
       "      <td>37.077772</td>\n",
       "      <td>88.609437</td>\n",
       "      <td>13676.957810</td>\n",
       "      <td>28.022851</td>\n",
       "      <td>35.192676</td>\n",
       "      <td>0.196941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>043ac50845d5</td>\n",
       "      <td>0.252107</td>\n",
       "      <td>3819.65177</td>\n",
       "      <td>120.201618</td>\n",
       "      <td>77.112203</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.685344</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>11.053708</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.122162</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>18.529584</td>\n",
       "      <td>82.416803</td>\n",
       "      <td>2094.262452</td>\n",
       "      <td>39.948656</td>\n",
       "      <td>90.493248</td>\n",
       "      <td>0.155829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>044fb8a146ec</td>\n",
       "      <td>0.380297</td>\n",
       "      <td>3733.04844</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>14.103738</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.942255</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>102.151980</td>\n",
       "      <td>...</td>\n",
       "      <td>8.153058</td>\n",
       "      <td>48.50134</td>\n",
       "      <td>0.121914</td>\n",
       "      <td>16.408728</td>\n",
       "      <td>146.109943</td>\n",
       "      <td>8524.370502</td>\n",
       "      <td>45.381316</td>\n",
       "      <td>36.262628</td>\n",
       "      <td>0.096614</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id        AB          AF          AH         AM        AR  \\\n",
       "0  000ff2bfdfe9  0.209377  3109.03329   85.200147  22.394407  8.138688   \n",
       "1  007255e47698  0.145282   978.76416   85.200147  36.968889  8.138688   \n",
       "2  013f2bd269f5  0.470030  2635.10654   85.200147  32.360553  8.138688   \n",
       "3  043ac50845d5  0.252107  3819.65177  120.201618  77.112203  8.138688   \n",
       "4  044fb8a146ec  0.380297  3733.04844   85.200147  14.103738  8.138688   \n",
       "\n",
       "         AX        AY         AZ          BC  ...        FL        FR  \\\n",
       "0  0.699861  0.025578   9.812214    5.555634  ...  7.298162   1.73855   \n",
       "1  3.632190  0.025578  13.517790    1.229900  ...  0.173229   0.49706   \n",
       "2  6.732840  0.025578  12.824570    1.229900  ...  7.709560   0.97556   \n",
       "3  3.685344  0.025578  11.053708    1.229900  ...  6.122162   0.49706   \n",
       "4  3.942255  0.054810   3.396778  102.151980  ...  8.153058  48.50134   \n",
       "\n",
       "         FS         GB          GE            GF         GH         GI  \\\n",
       "0  0.094822  11.339138   72.611063   2003.810319  22.136229  69.834944   \n",
       "1  0.568932   9.292698   72.611063  27981.562750  29.135430  32.131996   \n",
       "2  1.198821  37.077772   88.609437  13676.957810  28.022851  35.192676   \n",
       "3  0.284466  18.529584   82.416803   2094.262452  39.948656  90.493248   \n",
       "4  0.121914  16.408728  146.109943   8524.370502  45.381316  36.262628   \n",
       "\n",
       "          GL  Class  \n",
       "0   0.120343      1  \n",
       "1  21.978000      0  \n",
       "2   0.196941      0  \n",
       "3   0.155829      0  \n",
       "4   0.096614      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(f'{path}/train.csv', low_memory=False)\n",
    "df_test = pd.read_csv(f'{path}/test.csv', low_memory=False)\n",
    "greeks = pd.read_csv(f'{path}/greeks.csv', low_memory=False)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3528aa41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN',\n",
       "       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS',\n",
       "       'CU', 'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n",
       "       'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI',\n",
       "       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3244e6e5",
   "metadata": {},
   "source": [
    "We can now examine the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d653fccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>...</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>617.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.477149</td>\n",
       "      <td>3502.013221</td>\n",
       "      <td>118.624513</td>\n",
       "      <td>38.968552</td>\n",
       "      <td>10.128242</td>\n",
       "      <td>5.545576</td>\n",
       "      <td>0.060320</td>\n",
       "      <td>10.566447</td>\n",
       "      <td>8.053012</td>\n",
       "      <td>5350.388655</td>\n",
       "      <td>...</td>\n",
       "      <td>5.433199</td>\n",
       "      <td>3.533905</td>\n",
       "      <td>0.421501</td>\n",
       "      <td>20.724856</td>\n",
       "      <td>131.714987</td>\n",
       "      <td>14679.595398</td>\n",
       "      <td>31.489716</td>\n",
       "      <td>50.584437</td>\n",
       "      <td>8.530961</td>\n",
       "      <td>0.175041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.468388</td>\n",
       "      <td>2300.322717</td>\n",
       "      <td>127.838950</td>\n",
       "      <td>69.728226</td>\n",
       "      <td>10.518877</td>\n",
       "      <td>2.551696</td>\n",
       "      <td>0.416817</td>\n",
       "      <td>4.350645</td>\n",
       "      <td>65.166943</td>\n",
       "      <td>3021.326641</td>\n",
       "      <td>...</td>\n",
       "      <td>11.496257</td>\n",
       "      <td>50.181948</td>\n",
       "      <td>1.305365</td>\n",
       "      <td>9.991907</td>\n",
       "      <td>144.181524</td>\n",
       "      <td>19352.959387</td>\n",
       "      <td>9.864239</td>\n",
       "      <td>36.266251</td>\n",
       "      <td>10.327010</td>\n",
       "      <td>0.380310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.081187</td>\n",
       "      <td>192.593280</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>3.177522</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>1693.624320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.497060</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>4.102182</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>13.038894</td>\n",
       "      <td>9.432735</td>\n",
       "      <td>0.897628</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.252107</td>\n",
       "      <td>2197.345480</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>12.270314</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>4.128294</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>8.129580</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4155.702870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.497060</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>14.036718</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2798.992584</td>\n",
       "      <td>25.034888</td>\n",
       "      <td>23.011684</td>\n",
       "      <td>0.124392</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.354659</td>\n",
       "      <td>3120.318960</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>20.533110</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>5.031912</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>10.461320</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4997.960730</td>\n",
       "      <td>...</td>\n",
       "      <td>3.028141</td>\n",
       "      <td>1.131000</td>\n",
       "      <td>0.250601</td>\n",
       "      <td>18.771436</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>7838.273610</td>\n",
       "      <td>30.608946</td>\n",
       "      <td>41.007968</td>\n",
       "      <td>0.337827</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.559763</td>\n",
       "      <td>4361.637390</td>\n",
       "      <td>113.739540</td>\n",
       "      <td>39.139886</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.431634</td>\n",
       "      <td>0.036845</td>\n",
       "      <td>12.969516</td>\n",
       "      <td>5.081244</td>\n",
       "      <td>6035.885700</td>\n",
       "      <td>...</td>\n",
       "      <td>6.238814</td>\n",
       "      <td>1.512060</td>\n",
       "      <td>0.535067</td>\n",
       "      <td>25.608406</td>\n",
       "      <td>127.591671</td>\n",
       "      <td>19035.709240</td>\n",
       "      <td>36.863947</td>\n",
       "      <td>67.931664</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.161666</td>\n",
       "      <td>28688.187660</td>\n",
       "      <td>1910.123198</td>\n",
       "      <td>630.518230</td>\n",
       "      <td>178.943634</td>\n",
       "      <td>38.270880</td>\n",
       "      <td>10.315851</td>\n",
       "      <td>38.971568</td>\n",
       "      <td>1463.693448</td>\n",
       "      <td>53060.599240</td>\n",
       "      <td>...</td>\n",
       "      <td>137.932739</td>\n",
       "      <td>1244.227020</td>\n",
       "      <td>31.365763</td>\n",
       "      <td>135.781294</td>\n",
       "      <td>1497.351958</td>\n",
       "      <td>143790.071200</td>\n",
       "      <td>81.210825</td>\n",
       "      <td>191.194764</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               AB            AF           AH          AM          AR  \\\n",
       "count  617.000000    617.000000   617.000000  617.000000  617.000000   \n",
       "mean     0.477149   3502.013221   118.624513   38.968552   10.128242   \n",
       "std      0.468388   2300.322717   127.838950   69.728226   10.518877   \n",
       "min      0.081187    192.593280    85.200147    3.177522    8.138688   \n",
       "25%      0.252107   2197.345480    85.200147   12.270314    8.138688   \n",
       "50%      0.354659   3120.318960    85.200147   20.533110    8.138688   \n",
       "75%      0.559763   4361.637390   113.739540   39.139886    8.138688   \n",
       "max      6.161666  28688.187660  1910.123198  630.518230  178.943634   \n",
       "\n",
       "               AX          AY          AZ           BC           BD   ...  \\\n",
       "count  617.000000  617.000000  617.000000   617.000000    617.000000  ...   \n",
       "mean     5.545576    0.060320   10.566447     8.053012   5350.388655  ...   \n",
       "std      2.551696    0.416817    4.350645    65.166943   3021.326641  ...   \n",
       "min      0.699861    0.025578    3.396778     1.229900   1693.624320  ...   \n",
       "25%      4.128294    0.025578    8.129580     1.229900   4155.702870  ...   \n",
       "50%      5.031912    0.025578   10.461320     1.229900   4997.960730  ...   \n",
       "75%      6.431634    0.036845   12.969516     5.081244   6035.885700  ...   \n",
       "max     38.270880   10.315851   38.971568  1463.693448  53060.599240  ...   \n",
       "\n",
       "               FL           FR          FS          GB           GE  \\\n",
       "count  616.000000   617.000000  615.000000  617.000000   617.000000   \n",
       "mean     5.433199     3.533905    0.421501   20.724856   131.714987   \n",
       "std     11.496257    50.181948    1.305365    9.991907   144.181524   \n",
       "min      0.173229     0.497060    0.067730    4.102182    72.611063   \n",
       "25%      0.173229     0.497060    0.067730   14.036718    72.611063   \n",
       "50%      3.028141     1.131000    0.250601   18.771436    72.611063   \n",
       "75%      6.238814     1.512060    0.535067   25.608406   127.591671   \n",
       "max    137.932739  1244.227020   31.365763  135.781294  1497.351958   \n",
       "\n",
       "                  GF          GH          GI          GL       Class  \n",
       "count     617.000000  617.000000  617.000000  616.000000  617.000000  \n",
       "mean    14679.595398   31.489716   50.584437    8.530961    0.175041  \n",
       "std     19352.959387    9.864239   36.266251   10.327010    0.380310  \n",
       "min        13.038894    9.432735    0.897628    0.001129    0.000000  \n",
       "25%      2798.992584   25.034888   23.011684    0.124392    0.000000  \n",
       "50%      7838.273610   30.608946   41.007968    0.337827    0.000000  \n",
       "75%     19035.709240   36.863947   67.931664   21.978000    0.000000  \n",
       "max    143790.071200   81.210825  191.194764   21.978000    1.000000  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a7ef9c",
   "metadata": {},
   "source": [
    "We see that the mean of the dependant column `Class` is much closer to zero than one. This means that the observations with a positive diagnosis are smaller in proportion in the training data. We confirm this by plotting a pie chart for column `Class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95e14983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "df_train.Class.value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05141064",
   "metadata": {},
   "source": [
    "We also check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6263cd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BQ    60\n",
       "CB     2\n",
       "CC     3\n",
       "DU     1\n",
       "EL    60\n",
       "FC     1\n",
       "FL     1\n",
       "FS     2\n",
       "GL     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nulls = df_train.isna().sum()\n",
    "df_nulls[df_nulls > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5688f44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 617 entries, 0 to 616\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Id      617 non-null    object \n",
      " 1   AB      617 non-null    float64\n",
      " 2   AF      617 non-null    float64\n",
      " 3   AH      617 non-null    float64\n",
      " 4   AM      617 non-null    float64\n",
      " 5   AR      617 non-null    float64\n",
      " 6   AX      617 non-null    float64\n",
      " 7   AY      617 non-null    float64\n",
      " 8   AZ      617 non-null    float64\n",
      " 9   BC      617 non-null    float64\n",
      " 10  BD      617 non-null    float64\n",
      " 11  BN      617 non-null    float64\n",
      " 12  BP      617 non-null    float64\n",
      " 13  BQ      557 non-null    float64\n",
      " 14  BR      617 non-null    float64\n",
      " 15  BZ      617 non-null    float64\n",
      " 16  CB      615 non-null    float64\n",
      " 17  CC      614 non-null    float64\n",
      " 18  CD      617 non-null    float64\n",
      " 19  CF      617 non-null    float64\n",
      " 20  CH      617 non-null    float64\n",
      " 21  CL      617 non-null    float64\n",
      " 22  CR      617 non-null    float64\n",
      " 23  CS      617 non-null    float64\n",
      " 24  CU      617 non-null    float64\n",
      " 25  CW      617 non-null    float64\n",
      " 26  DA      617 non-null    float64\n",
      " 27  DE      617 non-null    float64\n",
      " 28  DF      617 non-null    float64\n",
      " 29  DH      617 non-null    float64\n",
      " 30  DI      617 non-null    float64\n",
      " 31  DL      617 non-null    float64\n",
      " 32  DN      617 non-null    float64\n",
      " 33  DU      616 non-null    float64\n",
      " 34  DV      617 non-null    float64\n",
      " 35  DY      617 non-null    float64\n",
      " 36  EB      617 non-null    float64\n",
      " 37  EE      617 non-null    float64\n",
      " 38  EG      617 non-null    float64\n",
      " 39  EH      617 non-null    float64\n",
      " 40  EJ      617 non-null    object \n",
      " 41  EL      557 non-null    float64\n",
      " 42  EP      617 non-null    float64\n",
      " 43  EU      617 non-null    float64\n",
      " 44  FC      616 non-null    float64\n",
      " 45  FD      617 non-null    float64\n",
      " 46  FE      617 non-null    float64\n",
      " 47  FI      617 non-null    float64\n",
      " 48  FL      616 non-null    float64\n",
      " 49  FR      617 non-null    float64\n",
      " 50  FS      615 non-null    float64\n",
      " 51  GB      617 non-null    float64\n",
      " 52  GE      617 non-null    float64\n",
      " 53  GF      617 non-null    float64\n",
      " 54  GH      617 non-null    float64\n",
      " 55  GI      617 non-null    float64\n",
      " 56  GL      616 non-null    float64\n",
      " 57  Class   617 non-null    int64  \n",
      "dtypes: float64(55), int64(1), object(2)\n",
      "memory usage: 279.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8820f124",
   "metadata": {},
   "source": [
    " # Data Processing\n",
    " \n",
    "We'll do some simple processing. We'll replace the categorical columns `EJ` and `Id` with numeric codes representing their levels. We'll have two sets of train/test datasets, with nulls and without nulls. We'll also add in the date column `Epsilon` from greeks data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7fad414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dates = greeks.Epsilon.copy()\n",
    "dates = dates.map(lambda x: datetime.strptime(x, '%m/%d/%Y').toordinal() if x.lower() != \"unknown\" else np.nan)\n",
    "max_date = dates.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec24e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Epsilon\"] = dates\n",
    "df_test[\"Epsilon\"] = max_date + 1\n",
    "df_train_na = df_train.copy()\n",
    "df_test_na = df_test.copy()\n",
    "\n",
    "modes = df_train.mode().iloc[0]\n",
    "df_train.fillna(modes, inplace=True)\n",
    "df_test.fillna(modes, inplace=True)\n",
    "\n",
    "def process_data(df):\n",
    "    df[\"EJ\"] = pd.Categorical(df.EJ).codes\n",
    "    df[\"Id\"] = pd.Categorical(df.Id).codes\n",
    "\n",
    "\n",
    "for df in [df_train, df_train_na, df_test, df_test_na]:\n",
    "    process_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1216aec3",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f833160b",
   "metadata": {},
   "source": [
    "Because of the small dataset size, we'll use stratified K-fold for our train/test splits. \n",
    "\n",
    "The competition uses the balanced log loss metric which is explained more [here][0]. For our purposes, we'll use the simple implementation.\n",
    "\n",
    "[0]: https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/422442"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e769bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    nc = np.bincount(y_true)\n",
    "    return log_loss(y_true, y_pred, sample_weight = 1/nc[y_true], eps=1e-15)\n",
    "\n",
    "def m_log_loss(model, xs, y): return balanced_log_loss(np.array(y), np.array(model.predict(xs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db709e2f",
   "metadata": {},
   "source": [
    "For each fold, we train and validate a model and collect the metrics. We use k-fold validation because of the small dataset size. Additionally, within each fold, we oversample the positive classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1c5c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "ycol = \"Class\"\n",
    "xcols = [c for c in df_train.columns if not c in [ycol]]\n",
    "\n",
    "def x_y(df):\n",
    "    y = df[ycol]\n",
    "    x = df[xcols]\n",
    "    return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe30d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "\n",
    "def get_folds(k_fold, index, y):\n",
    "    return [splits for splits in k_fold.split(index, y)]\n",
    "\n",
    "def evaluate_model(m, df, train_ids, val_ids):\n",
    "    train_xy, valid_xy = df.iloc[train_ids], df.iloc[val_ids]\n",
    "    \n",
    "    train_x, train_y = x_y(train_xy)\n",
    "    val_x, val_y = x_y(valid_xy)\n",
    "            \n",
    "    m.fit(train_x, train_y) \n",
    "        \n",
    "    preds = m.predict_proba(val_x)\n",
    "    class1_preds = preds[:,1]\n",
    "    logloss = balanced_log_loss(val_y, class1_preds)\n",
    "   \n",
    "    return m, logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e343b82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    509\n",
       "1    108\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = df_train.Class.value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7d0bca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 0.. fold: 1.. fold: 2.. fold: 3.. fold: 4.. fold: 0.. fold: 1.. fold: 2.. fold: 3.. fold: 4.. fold: 0.. fold: 1.. fold: 2.. fold: 3.. fold: 4.. fold: 0.. [LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 86, number of negative: 407\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7607\n",
      "[LightGBM] [Info] Number of data points in the train set: 493, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174442 -> initscore=-1.554466\n",
      "[LightGBM] [Info] Start training from score -1.554466\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1.. [LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 86, number of negative: 407\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7534\n",
      "[LightGBM] [Info] Number of data points in the train set: 493, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174442 -> initscore=-1.554466\n",
      "[LightGBM] [Info] Start training from score -1.554466\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "fold: 2.. [LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 86, number of negative: 408\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7535\n",
      "[LightGBM] [Info] Number of data points in the train set: 494, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.174089 -> initscore=-1.556920\n",
      "[LightGBM] [Info] Start training from score -1.556920\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "fold: 3.. [LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 87, number of negative: 407\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7536\n",
      "[LightGBM] [Info] Number of data points in the train set: 494, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.176113 -> initscore=-1.542905\n",
      "[LightGBM] [Info] Start training from score -1.542905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "fold: 4.. [LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 87, number of negative: 407\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7536\n",
      "[LightGBM] [Info] Number of data points in the train set: 494, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.176113 -> initscore=-1.542905\n",
      "[LightGBM] [Info] Start training from score -1.542905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "s_kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "#rs_kfold = RepeatedStratifiedKFold()\n",
    "\n",
    "folds = get_folds(s_kfold, df_train.index, df_train.Class)\n",
    "\n",
    "tabpfn_params = dict(device='cpu', N_ensemble_configurations=16) if not is_kaggle else dict(device='cuda:0', N_ensemble_configurations=64)\n",
    "tabpfn = TabPFNClassifier(**tabpfn_params)\n",
    "\n",
    "xgb_params = {'colsample_bytree': 0.8757972257439255, 'gamma': 0.11135738771999848, 'max_depth': 7, 'min_child_weight': 3, 'reg_alpha': 0.4833998914998038, 'reg_lambda': 0.006223568555619563, 'subsample': 0.7056434340275685}\n",
    "xgb = XGBClassifier(eval_metric=\"logloss\", scale_pos_weight=class_counts[0]/class_counts[1])#, **xgb_params)\n",
    "\n",
    "#lgbm = LGBMClassifier(metric=\"binary_logloss\", scale_pos_weight=class_counts[0]/class_counts[1], max_depth=9, num_leaves=15)\n",
    "lgbm = LGBMClassifier(metric=\"binary_logloss\", scale_pos_weight=class_counts[0]/class_counts[1])\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(class_weight=\"balanced\")\n",
    "\n",
    "kfold_params = [('xgb', xgb), ('hgb', hgb), ('tabpfn', tabpfn), ('lgbm', lgbm)]\n",
    "kfold_results = {}\n",
    "model_scores = []  # store a tuple of (score, fold, model)\n",
    "\n",
    "for name, m in kfold_params:\n",
    "    \n",
    "    results = defaultdict(list)\n",
    "    if name == \"lgbm\":\n",
    "        kfold_df = df_train\n",
    "    else:\n",
    "        kfold_df = df_train_na\n",
    "    \n",
    "    for i, (x_split, y_split) in enumerate(folds):\n",
    "        print(f\"fold: {i}.. \", end=\"\")\n",
    "    \n",
    "        model, logloss = evaluate_model(m, kfold_df, x_split, y_split)\n",
    "        results['models'].append(model)\n",
    "        results['loglosses'].append(logloss)\n",
    "        \n",
    "        model_scores.append((logloss, i, model))\n",
    "    \n",
    "    results['mean_logloss'] = np.mean(results['loglosses'])\n",
    "    \n",
    "    kfold_results[name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db977d9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgb': defaultdict(list,\n",
       "             {'models': [XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                             colsample_bylevel=None, colsample_bynode=None,\n",
       "                             colsample_bytree=None, early_stopping_rounds=None,\n",
       "                             enable_categorical=False, eval_metric='logloss',\n",
       "                             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                             importance_type=None, interaction_constraints=None,\n",
       "                             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "                             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "                             num_parallel_tree=None, predictor=None, random_state=None, ...),\n",
       "               XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                             colsample_bylevel=None, colsample_bynode=None,\n",
       "                             colsample_bytree=None, early_stopping_rounds=None,\n",
       "                             enable_categorical=False, eval_metric='logloss',\n",
       "                             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                             importance_type=None, interaction_constraints=None,\n",
       "                             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "                             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "                             num_parallel_tree=None, predictor=None, random_state=None, ...),\n",
       "               XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                             colsample_bylevel=None, colsample_bynode=None,\n",
       "                             colsample_bytree=None, early_stopping_rounds=None,\n",
       "                             enable_categorical=False, eval_metric='logloss',\n",
       "                             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                             importance_type=None, interaction_constraints=None,\n",
       "                             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "                             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "                             num_parallel_tree=None, predictor=None, random_state=None, ...),\n",
       "               XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                             colsample_bylevel=None, colsample_bynode=None,\n",
       "                             colsample_bytree=None, early_stopping_rounds=None,\n",
       "                             enable_categorical=False, eval_metric='logloss',\n",
       "                             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                             importance_type=None, interaction_constraints=None,\n",
       "                             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "                             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "                             num_parallel_tree=None, predictor=None, random_state=None, ...),\n",
       "               XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                             colsample_bylevel=None, colsample_bynode=None,\n",
       "                             colsample_bytree=None, early_stopping_rounds=None,\n",
       "                             enable_categorical=False, eval_metric='logloss',\n",
       "                             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                             importance_type=None, interaction_constraints=None,\n",
       "                             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "                             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "                             num_parallel_tree=None, predictor=None, random_state=None, ...)],\n",
       "              'loglosses': [0.20949130232372967,\n",
       "               0.3686017151864909,\n",
       "               0.3323325319327827,\n",
       "               0.3545970323888008,\n",
       "               0.2766280996794353],\n",
       "              'mean_logloss': 0.30833013630224787}),\n",
       " 'hgb': defaultdict(list,\n",
       "             {'models': [HistGradientBoostingClassifier(class_weight='balanced'),\n",
       "               HistGradientBoostingClassifier(class_weight='balanced'),\n",
       "               HistGradientBoostingClassifier(class_weight='balanced'),\n",
       "               HistGradientBoostingClassifier(class_weight='balanced'),\n",
       "               HistGradientBoostingClassifier(class_weight='balanced')],\n",
       "              'loglosses': [0.16884874161089844,\n",
       "               0.41380690654205804,\n",
       "               0.3488417222992145,\n",
       "               0.2788695938327788,\n",
       "               0.26120641734066374],\n",
       "              'mean_logloss': 0.2943146763251227}),\n",
       " 'tabpfn': defaultdict(list,\n",
       "             {'models': [TabPFNClassifier(N_ensemble_configurations=16),\n",
       "               TabPFNClassifier(N_ensemble_configurations=16),\n",
       "               TabPFNClassifier(N_ensemble_configurations=16),\n",
       "               TabPFNClassifier(N_ensemble_configurations=16),\n",
       "               TabPFNClassifier(N_ensemble_configurations=16)],\n",
       "              'loglosses': [0.2887273885969553,\n",
       "               0.24007419633469843,\n",
       "               0.5170791319952166,\n",
       "               0.43032819557445745,\n",
       "               0.44126827267794455],\n",
       "              'mean_logloss': 0.3834954370358544}),\n",
       " 'lgbm': defaultdict(list,\n",
       "             {'models': [LGBMClassifier(metric='binary_logloss', scale_pos_weight=4.712962962962963),\n",
       "               LGBMClassifier(metric='binary_logloss', scale_pos_weight=4.712962962962963),\n",
       "               LGBMClassifier(metric='binary_logloss', scale_pos_weight=4.712962962962963),\n",
       "               LGBMClassifier(metric='binary_logloss', scale_pos_weight=4.712962962962963),\n",
       "               LGBMClassifier(metric='binary_logloss', scale_pos_weight=4.712962962962963)],\n",
       "              'loglosses': [0.4442740837997466,\n",
       "               0.5132369720531473,\n",
       "               0.4477155219585705,\n",
       "               0.5750244429029769,\n",
       "               0.3019228004820611],\n",
       "              'mean_logloss': 0.4564347642393004})}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007c0f1",
   "metadata": {},
   "source": [
    "Below is the overall mean prediction by the kfold ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70519530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3606437534756314"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembles = ['xgb', 'hgb', 'tabpfn', 'lgbm']\n",
    "all_loglosses = []\n",
    "[all_loglosses.extend(kfold_results[k]['loglosses']) for k in ensembles]\n",
    "np.mean(all_loglosses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721fd31e",
   "metadata": {},
   "source": [
    "We can order the models by their logloss score. For example, the top 7 performing models across all the folds are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9974725e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.16884874161089844,\n",
       "  0,\n",
       "  HistGradientBoostingClassifier(class_weight='balanced')),\n",
       " (0.20949130232372967,\n",
       "  0,\n",
       "  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric='logloss',\n",
       "                feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                importance_type=None, interaction_constraints=None,\n",
       "                learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "                max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "                num_parallel_tree=None, predictor=None, random_state=None, ...)),\n",
       " (0.24007419633469843, 1, TabPFNClassifier(N_ensemble_configurations=16)),\n",
       " (0.26120641734066374,\n",
       "  4,\n",
       "  HistGradientBoostingClassifier(class_weight='balanced')),\n",
       " (0.2766280996794353,\n",
       "  4,\n",
       "  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric='logloss',\n",
       "                feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "                importance_type=None, interaction_constraints=None,\n",
       "                learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "                max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "                max_leaves=None, min_child_weight=None, missing=nan,\n",
       "                monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "                num_parallel_tree=None, predictor=None, random_state=None, ...)),\n",
       " (0.2788695938327788,\n",
       "  3,\n",
       "  HistGradientBoostingClassifier(class_weight='balanced')),\n",
       " (0.2887273885969553, 0, TabPFNClassifier(N_ensemble_configurations=16))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "top_7 = heapq.nsmallest(7, model_scores)\n",
    "top_7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d63700",
   "metadata": {},
   "source": [
    "Looks like fold 2 doesn't produce any top 7 models. We can cross-validate the top 7 models across all the samples to see which give the best average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82c94e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = [m for _, _, m in top_7]\n",
    "top_models\n",
    "\n",
    "top_scores, top_2_scores, top_3_scores, top_4_scores, top_5_scores, top_6_scores, top_7_scores = [], [], [], [], [], [], []\n",
    "\n",
    "for x_split, y_split in folds:    \n",
    "    \n",
    "    for i, m in enumerate(top_models):\n",
    "        if 'TabPFNClassifier' in str(type(m)):\n",
    "            val_df = df_train.iloc[y_split]\n",
    "        else:\n",
    "            val_df = df_train_na.iloc[y_split]\n",
    "        \n",
    "        X, y = x_y(val_df)\n",
    "        preds = m.predict_proba(X)\n",
    "        class1_preds = preds[:,1]\n",
    "        logloss = balanced_log_loss(y, class1_preds)\n",
    "        \n",
    "        # append to appropriate results lists\n",
    "        if i == 0:\n",
    "            top_scores.append(logloss)\n",
    "        if i <= 1:\n",
    "            top_2_scores.append(logloss)\n",
    "        if i <= 2:\n",
    "            top_3_scores.append(logloss)\n",
    "        if i <= 3:\n",
    "            top_4_scores.append(logloss)\n",
    "        if i <= 4:\n",
    "            top_5_scores.append(logloss)\n",
    "        if i <= 5:\n",
    "            top_6_scores.append(logloss)\n",
    "        top_7_scores.append(logloss)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ab53ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0014148460733463659,\n",
       " 0.0030775070132614837,\n",
       " 0.05328321905207482,\n",
       " 0.0014148460733463659,\n",
       " 0.0030775070132614837,\n",
       " 0.0014148460733463659,\n",
       " 0.05328321905207482,\n",
       " 0.0015307941000739203,\n",
       " 0.0037892437853112777,\n",
       " 0.04938992949818645,\n",
       " 0.0015307941000739203,\n",
       " 0.0037892437853112777,\n",
       " 0.0015307941000739203,\n",
       " 0.04938992949818645,\n",
       " 0.0014106921216495598,\n",
       " 0.003693372698416881,\n",
       " 0.059689843803636435,\n",
       " 0.0014106921216495598,\n",
       " 0.003693372698416881,\n",
       " 0.0014106921216495598,\n",
       " 0.059689843803636435,\n",
       " 0.0017017442638975616,\n",
       " 0.0035331665255165317,\n",
       " 0.05651543133104301,\n",
       " 0.0017017442638975616,\n",
       " 0.0035331665255165317,\n",
       " 0.0017017442638975616,\n",
       " 0.05651543133104301,\n",
       " 0.26120641734066374,\n",
       " 0.2766280996794353,\n",
       " 0.45617808840458196,\n",
       " 0.26120641734066374,\n",
       " 0.2766280996794353,\n",
       " 0.26120641734066374,\n",
       " 0.45617808840458196]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_7_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946d6468",
   "metadata": {},
   "source": [
    "Looks like the last sample was the hardest one for all the selected models to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4607f3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.053452898779926226,\n",
       " 0.05579858836015726,\n",
       " 0.08220282637940635,\n",
       " 0.07501534447953633,\n",
       " 0.07164113117170672,\n",
       " 0.06860975910640996,\n",
       " 0.07809569386519491]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_collections = [top_scores, top_2_scores, top_3_scores, top_4_scores, top_5_scores, top_6_scores, top_7_scores]\n",
    "all_avg_scores = [np.mean(scores) for scores in score_collections]\n",
    "all_avg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b0d745",
   "metadata": {},
   "source": [
    "This [discussion][9] mentions a particular observation that is particularly hard to predict, Id `cf5439add02c`. We can observe what our top models predict for this one.\n",
    "\n",
    "[9]: https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/430475"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e125398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>...</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>cf5439add02c</td>\n",
       "      <td>0.132463</td>\n",
       "      <td>1777.81186</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>18.591291</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>4.544667</td>\n",
       "      <td>0.11571</td>\n",
       "      <td>9.856328</td>\n",
       "      <td>8.531992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>2.03464</td>\n",
       "      <td>0.088049</td>\n",
       "      <td>17.320324</td>\n",
       "      <td>146.586979</td>\n",
       "      <td>12008.3796</td>\n",
       "      <td>29.116825</td>\n",
       "      <td>21.291016</td>\n",
       "      <td>21.978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id        AB          AF         AH         AM        AR  \\\n",
       "509  cf5439add02c  0.132463  1777.81186  85.200147  18.591291  8.138688   \n",
       "\n",
       "           AX       AY        AZ        BC  ...        FL       FR        FS  \\\n",
       "509  4.544667  0.11571  9.856328  8.531992  ...  0.173229  2.03464  0.088049   \n",
       "\n",
       "            GB          GE          GF         GH         GI      GL  Class  \n",
       "509  17.320324  146.586979  12008.3796  29.116825  21.291016  21.978      1  \n",
       "\n",
       "[1 rows x 58 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_raw = pd.read_csv(f'{path}/train.csv', low_memory=False)\n",
    "row = df_train_raw[df_train_raw.Id == \"cf5439add02c\"]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05aae8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([9.99634295e-01, 3.65704707e-04]),\n",
       " array([9.9968898e-01, 3.1100193e-04], dtype=float32),\n",
       " array([9.999666e-01, 3.332492e-05], dtype=float32),\n",
       " array([9.99634295e-01, 3.65704707e-04]),\n",
       " array([9.9968898e-01, 3.1100193e-04], dtype=float32),\n",
       " array([9.99634295e-01, 3.65704707e-04]),\n",
       " array([9.999666e-01, 3.332492e-05], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_idx = 509\n",
    "row_preds = []\n",
    "for m in top_models:\n",
    "    if 'TabPFNClassifier' in str(type(m)):\n",
    "        df = df_train\n",
    "    else:\n",
    "        df = df_train_na\n",
    "    row_df = df.filter(items=[row_idx], axis=0)\n",
    "    row_preds.append(m.predict_proba(row_df[xcols])[0])\n",
    "\n",
    "row_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d4dcd",
   "metadata": {},
   "source": [
    "Looks problematic here as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb406fb",
   "metadata": {},
   "source": [
    "\n",
    "# Submission\n",
    "\n",
    "We'll get predictions from the ensemble by averaging all the predictions from the individual models. It's possible that the top model alone could be overfitting. So we'll submit predictions from an ensemble of the top 6 models. This will balance both the score, and the available model types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "820555ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HistGradientBoostingClassifier(class_weight='balanced'),\n",
       " XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None,\n",
       "               learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "               num_parallel_tree=None, predictor=None, random_state=None, ...),\n",
       " TabPFNClassifier(N_ensemble_configurations=16),\n",
       " HistGradientBoostingClassifier(class_weight='balanced'),\n",
       " XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None,\n",
       "               learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "               max_leaves=None, min_child_weight=None, missing=nan,\n",
       "               monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "               num_parallel_tree=None, predictor=None, random_state=None, ...),\n",
       " HistGradientBoostingClassifier(class_weight='balanced')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_6_models = top_models[:6]\n",
    "top_6_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b90e2c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total preds: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.93422571, 0.06577427],\n",
       "       [0.934226  , 0.06577401],\n",
       "       [0.93422593, 0.06577406],\n",
       "       [0.93422557, 0.06577443],\n",
       "       [0.93422554, 0.06577445]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds = []\n",
    "\n",
    "for m in top_6_models:\n",
    "    if 'TabPFNClassifier' in str(type(m)):\n",
    "        t_df = df_test\n",
    "    else:\n",
    "        t_df = df_test_na\n",
    "    \n",
    "    final_preds.append(m.predict_proba(t_df[xcols]))\n",
    "\n",
    "\n",
    "print(f'total preds: {len(final_preds)}')\n",
    "avg_preds = np.stack(final_preds).mean(axis=0)\n",
    "avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e975005",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit=False\n",
    "if is_kaggle and submit:\n",
    "\n",
    "    df_submission = pd.read_csv(f\"{path}/sample_submission.csv\")\n",
    "    df_submission[[\"class_0\", \"class_1\"]] = avg_preds\n",
    "    df_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba674d02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
